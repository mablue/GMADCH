\documentclass[a4paper,12pt]{article}
\usepackage{amsmath,amssymb,graphicx,hyperref}
\usepackage{geometry}
\geometry{margin=1in}

\title{GMADCH: H-Design Modularization for Software Systems with Incoherent Call Graphs}
\author{
  Masoud Azizi\textsuperscript{1},
  Dr. Habib Izadkhah\textsuperscript{2},
  Prof. Ayaz Issazadeh\textsuperscript{3}\\
  \small{
  \textsuperscript{1}Department of Computer Science, Institute of Higher Education of Tabriz Scholars, Tabriz\\
  \textsuperscript{2}Department of Computer Science, Faculty of Mathematical Sciences, Tabriz University, Tabriz\\
  \textsuperscript{3}Department of Computer Science, Faculty of Mathematical Sciences, Tabriz University, Tabriz\\
  \texttt{mablue92@gmail.com}, \texttt{izadkhah@tabrizu.ac.ir}, \texttt{isazadeh@tabrizu.ac.ir}
  }
}
\date{October 2025}

\begin{document}
\maketitle

\begin{abstract}
Benchmarking and modularizing software systems with incoherent call graphs is a challenging nonlinear problem with deep implications for maintainability and architecture. GMADCH introduces a novel H-design algorithm based on Levenshtein distance and vocabulary congruence, enabling logical grouping by conceptual similarity. This article presents the mathematical foundation, algorithmic details, evaluation, and comparison with prior graph-based and clustering approaches.
\end{abstract}

\section{Introduction}
Modern software systems often contain modules with weak or absent interconnections, resulting in incoherent call graphs. Graph-based modularization approaches (e.g., \cite{Izadkhah2016,Pourasghar2020}) struggle with such systems, resorting to random assignment or heuristic clustering. GMADCH offers a text-based similarity approach, leveraging Levenshtein distance and vocabulary congruence to enable logical, maintainable clustering.

\section{Related Work and Background}
Software modularization, clustering, and architecture recovery have been extensively studied. Graph-based algorithms (e.g., depth-based, hierarchical, evolutionary) and string matching methods (e.g., Levenshtein, Jaccard, Ellenberg) form the foundation for systems like GMADCH. See \cite{Izadkhah2016,SokalMichener1958,Gusfield1997,Navarro2001,Andritsos2005,Pourasghar2020} for core methodologies.

\section{Definitions}
\subsection{Call Dependency Graph}
A call dependency graph $G = (V, E)$ represents software entities (files, classes, functions) as nodes $V$ and their relationships (calls, references) as edges $E$.

\subsection{Levenshtein Distance}
Given two strings $s_1, s_2$, the Levenshtein distance $d_L(s_1, s_2)$ is the minimum number of edit operations (insertions, deletions, substitutions) needed to transform $s_1$ into $s_2$ \cite{Levenshtein1966}. Formally,
\begin{equation}
d_L(s_1, s_2) = 
\begin{cases}
|s_1|, & |s_2| = 0 \\
|s_2|, & |s_1| = 0 \\
\min \begin{cases}
d_L(\text{tail}(s_1), s_2) + 1 \\
d_L(s_1, \text{tail}(s_2)) + 1 \\
d_L(\text{tail}(s_1), \text{tail}(s_2)) + [s_1[0] \neq s_2[0]]
\end{cases}
\end{cases}
\end{equation}

\subsection{Vocabulary Congruence Scoring (H-Design)}
For each word $w$ in a file, its conceptual H-design score is:
\begin{equation}
\text{score}(w) = \text{freq}(w) + \sum_{\substack{w' \in D \\ w' \neq w}} \frac{\text{freq}(w')}{d_L(w, w')}
\end{equation}
where $D$ is the dictionary (global or user-provided).

\section{Algorithm Description}
\subsection{Preprocessing}
\begin{itemize}
    \item Extract all words from code files, excluding short words and programming keywords.
    \item Build dictionary $D$ (auto or user-provided list).
\end{itemize}

\subsection{Scoring and Tag Selection}
For each code file:
\begin{itemize}
    \item Calculate $\text{score}(w)$ for all words $w$.
    \item Select top-$k$ tags (default $k=3$) per file.
\end{itemize}

\subsection{Folder Grouping and Clustering}
Files are grouped by folder and shared tags, revealing conceptual clusters and aiding maintainability.

\section{Mathematical Formalism}
\subsection{Similarity Matrix}
Let $S_{ij}$ represent similarity between entities $i$ and $j$:
\begin{equation}
S_{ij} = 1 - \frac{d_L(w_i, w_j)}{\max_{i,j} d_L(w_i, w_j)}
\end{equation}
This matrix underlies hierarchical clustering and modularization.

\subsection{Modularization Quality}
Following \cite{Izadkhah2016}, modularization quality $MQ$:
\begin{equation}
MQ = \frac{i}{i + j}
\end{equation}
where $i$ is internal edges, $j$ is external edges.

\subsection{Clustering Algorithms}
GMADCH relates to hierarchical clustering (UPGMA, WPGMA), centroid linkage, and K-means/K-medoids methods \cite{SokalMichener1958,Macqueen1967,Steinhaus1957,Forgy1965}.

\section{Evaluation}
We evaluated GMADCH on large open-source systems (e.g., Microsoft Calculator, financial trading platforms). Compared to previous graph-based and random modularization algorithms, GMADCH improved MoJo, MoJoFM, reduced clustering error, and enhanced maintainability.

\subsection{Results}
\begin{table}[h!]
\centering
\begin{tabular}{lccc}
\hline
Algorithm & MoJo & MoJoFM & Time (s) \\
\hline
GMA (random) & 37.3 & 22.3 & 0.017 \\
GMADC (text-based) & 37.2 & 22.5 & 0.76 \\
GMADCH (H-design) & \textbf{34.7} & \textbf{29.2} & 0.82 \\
\hline
\end{tabular}
\caption{Comparison of modularization quality and performance.}
\end{table}

\section{Limitations}
- Levenshtein scoring can become computationally expensive for very large dictionaries; parallelization and filtering are used.
- Tag selection may be impacted by code style and documentation quality.
- Future work includes advanced similarity matrices and mapping to sparse graphs.

\section{Future Work}
- Applying Johnson's algorithm for sparse graphs \cite{Cormen1990}.
- Refining similarity measures with semantic and structural code analysis.
- Integrating clustering indices and optimizing for distributed computation.

\section{Conclusion}
GMADCH advances modularization for heterogeneous software, combining string metric theory and vocabulary analysis. The H-design approach connects entities by conceptual similarity, avoiding random clustering and enabling logical scaling of incoherent call graphs.

\section{References}
\bibliographystyle{plain}
\begin{thebibliography}{99}
\bibitem{Izadkhah2016} H. Izadkhah, I. Elgedawy and A. Isazadeh, "E-CDGM: An Evolutionary Call-Dependency Graph Modularization Approach for Software Systems," Cybernetics and Information Technologies, pp. 70-90, 2016.
\bibitem{Pourasghar2020} B. Pourasghar, H. Izadkhah, A. Isazadeh and S. Lotf, "A Graph-based Algorithm for Software Systems Modularization by Considering the Depth of Relationships," 2020.
\bibitem{Levenshtein1966} V.I. Levenshtein, "Binary codes capable of correcting deletions, insertions, and reversals," Soviet Physics Doklady, vol. 10, no. 8, pp. 707–710, 1966.
\bibitem{SokalMichener1958} R.R. Sokal, C.D. Michener, "A statistical method for evaluating systematic relationships," University of Kansas Scientific Bulletin, 1958.
\bibitem{Gusfield1997} D. Gusfield, "Algorithms on Strings, Trees and Sequences," Cambridge University Press, 1997.
\bibitem{Ducasse2009} S. Ducasse, D. Pollet, "Software architecture reconstruction: A process-oriented taxonomy," IEEE Transactions on Software Engineering, 35(4), 573–591, 2009.
\bibitem{Navarro2001} G. Navarro, "A guided tour to approximate string matching," ACM Computing Surveys, 33(1), 31–88, 2001.
\bibitem{Andritsos2005} P. Andritsos, V. Tzerpos, "Information-theoretic software clustering," IEEE Transactions on Software Engineering, 31(2), 150–165, 2005.
\bibitem{Cormen1990} T.H. Cormen, C.E. Leiserson, R.L. Rivest, "Introduction to Algorithms," MIT Press and McGraw-Hill, 1990.
\bibitem{EstivillCastro2002} V. Estivill-Castro, "Why so many clustering algorithms," ACM SIGKDD Explorations Newsletter, 4(1), 65–75, 2002.
\bibitem{Macqueen1967} J. Macqueen, "Some Methods for Classification and Analysis of Multivariate Observations," Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability, University of California Press, 1967.
\bibitem{Steinhaus1957} H. Steinhaus, "Sur la division des corps matériels en parties," Bull. Acad. Poland. Sci., 1957.
\bibitem{Forgy1965} E. Forgy, "Cluster analysis of multivariate data: efficiency versus interpretability of classifications," Biometrics, 1965.
\end{thebibliography}

\end{document}
